## ğŸ“„ DÃ©tection de Fraude â€“ Compte Rendu du Projet
<img width="400" height="250" alt="image" src="https://github.com/user-attachments/assets/a2c3ebce-f022-4246-843e-c58dcda56ea8" />

Par EL YESRI INASS 
<img width="100" height="150" alt="image" src="https://github.com/user-attachments/assets/8ff73355-eaf0-42d3-ac75-12fdc08df8d2" />

## 1. Introduction

Le fichier DATE.SET.csv constitue la base du projet Machine Learning.

Il contient :

un identifiant client (client_id)

une variable cible continue (target) comprise entre 0 et 1

Lâ€™objectif du projet est de dÃ©velopper un modÃ¨le prÃ©dictif capable dâ€™estimer ce score target pour de nouveaux clients aprÃ¨s enrichissement du dataset.

## Ce rapport suit le cahier des charges officiel :

dataset â†’ preprocessing â†’ EDA â†’ modÃ©lisation â†’ rÃ©sultats â†’ conclusion.

## 2. Le Dataset (Livrable 1)

## 2.1. Source & SÃ©lection

Fichier utilisÃ© : DATE.SET.csv

58 069 lignes

2 colonnes

Dataset adaptÃ© Ã  un problÃ¨me rÃ©aliste de scoring client, contrairement Ã  des jeux triviaux (Iris, Titanic).

## 2.2. ProblÃ©matique et type de tÃ¢che

## TÃ¢che : RÃ©gression supervisÃ©e

Objectif : prÃ©dire une variable target continue âˆˆ [0,1]

Application : scoring client, probabilitÃ©, intensitÃ©, risque.

## 2.3. Dictionnaire de donnÃ©es

Colonne	Type	RÃ´le	Description

client_id	string	ID Client	Identifiant unique (ex: test_Client_0)

# target	float64	Target	Score continu âˆˆ [0,1]

## ğŸ” Statistiques de base

Min â‰ˆ 0

Max â‰ˆ 1

Moyenne â‰ˆ 0.50

Ã‰cart-type â‰ˆ 0.29

## 3. MÃ©thodologie & Graphiques (Livrable 2+3)

## 3.1. PrÃ©-traitement (Preprocessing)
```python
import pandas as pd

df = pd.read_csv("DATE.SET.csv")
df.info()
df.describe()
df.duplicated().sum()
```
## ğŸ¯ Choix techniques justifiÃ©s :

Le dataset est propre mais devra Ãªtre enrichi.

client_id sera utilisÃ© pour joindre d'autres tables.

Aucun modÃ¨le nâ€™accepte les strings â†’ encodages nÃ©cessaires aprÃ¨s jointure.

Normalisation obligatoire si SVM, KNN ou MLP sont utilisÃ©s.

## 3.2. Analyse Exploratoire (EDA)

# ğŸ“Œ Graphique 1 â€” Histogramme de la variable cible
```python
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(7,4))
sns.histplot(df["target"], bins=30, kde=True)
plt.title("Distribution de la variable target")
plt.xlabel("Score target")
plt.ylabel("FrÃ©quence")
plt.show()
```
## InterprÃ©tation :

La distribution est quasi uniforme entre 0 et 1, mais une lÃ©gÃ¨re densitÃ© apparaÃ®t autour de 0.5.

Cela confirme :

une bonne variabilitÃ© pour la modÃ©lisation,

absence de dÃ©sÃ©quilibre,

pas de transformation de type log Ã  appliquer.

# ğŸ“ŒGraphique 2 â€” Boxplot de target (dÃ©tection dâ€™outliers)

```python
plt.figure(figsize=(6,3))
sns.boxplot(x=df["target"])
plt.title("Boxplot de la cible target")
plt.show()
```
## InterprÃ©tation :

Le boxplot montre :

aucune valeur aberrante extrÃªme,

une dispersion homogÃ¨ne.

Cela confirme que le dataset ne nÃ©cessite pas de traitement dâ€™outliers pour la cible.

# ğŸ“ŒGraphique 3 â€” Heatmap prÃ©liminaire (corrÃ©lations)

Ce graphique sera plus utile aprÃ¨s jointures mais on en illustre le fonctionnement :
```python
import numpy as np

plt.figure(figsize=(3,3))
corr = df[["target"]].corr()
sns.heatmap(corr, annot=True, cmap="Blues")
plt.title("CorrÃ©lation de la target (dataset initial)")
plt.show()
```
## InterprÃ©tation :

La corrÃ©lation nâ€™a de sens quâ€™avec plus de colonnes.

Dans la version finale du dataset (aprÃ¨s ajouts de features), cette heatmap permettra :

dâ€™identifier les variables explicatives pertinentes

de dÃ©tecter la multicolinÃ©aritÃ©,

dâ€™orienter le feature engineering.

# ğŸ“ŒGraphique 4 â€” Distribution cumulÃ©e (CDF)

```python
import numpy as np

plt.figure(figsize=(7,4))
sorted_target = np.sort(df["target"])
yvals = np.arange(len(sorted_target)) / float(len(sorted_target)-1)
plt.plot(sorted_target, yvals)
plt.title("Fonction de distribution cumulÃ©e â€“ target")
plt.xlabel("target")
plt.ylabel("ProbabilitÃ© cumulÃ©e")
plt.grid()
plt.show()
```
## InterprÃ©tation :

La CDF montre une progression rÃ©guliÃ¨re, confirmant que le score est Ã©talÃ© dans tout lâ€™intervalle [0,1].

Cela signifie quâ€™un modÃ¨le pourra apprendre des diffÃ©rences fines entre individus.

## 3.3. ModÃ©lisation (Machine Learning)

ğŸ”§ ModÃ¨les testÃ©s (3 minimum)

RÃ©gression LinÃ©aire

Random Forest Regressor

Gradient Boosting / XGBoost / LightGBM

# ğŸ” Validation

Cross-Validation K-Fold (k=5 ou 10)

GridSearchCV / RandomizedSearchCV

# ğŸ“Š Exemple de code de modÃ©lisation

```python
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

X = df.drop(columns=["target"])
y = df["target"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

models = {
    "LinearRegression": LinearRegression(),
    "RandomForest": RandomForestRegressor(),
    "GradientBoosting": GradientBoostingRegressor()
}

results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    results[name] = {
        "RMSE": np.sqrt(mean_squared_error(y_test, preds)),
        "R2": r2_score(y_test, preds)
    }

results
```
## 4. RÃ©sultats & Discussion

âš ï¸ Ã€ complÃ©ter avec tes rÃ©sultats rÃ©els une fois l'entraÃ®nement effectuÃ©.

 | ModÃ¨le              | RMSE | MAE  | RÂ²   |

 | ------------------- | ---- | ---- | ---- |

 | RÃ©gression LinÃ©aire | TODO | TODO | TODO |

 | Random Forest       | TODO | TODO | TODO |

 | Gradient Boosting   | TODO | TODO | TODO |

# 4.2. Analyse des rÃ©sidus (Graphique)
```python

import matplotlib.pyplot as plt

model = GradientBoostingRegressor().fit(X_train, y_train)
preds = model.predict(X_test)
residuals = y_test - preds

plt.figure(figsize=(7,4))
sns.histplot(residuals, bins=30, kde=True)
plt.title("Distribution des rÃ©sidus")
plt.xlabel("Erreur (y_true - y_pred)")
plt.show()
```
## InterprÃ©tation :

Un rÃ©sidu centrÃ© autour de 0 â†’ modÃ¨le non biaisÃ©

Dispersion faible â†’ modÃ¨le prÃ©cis

Distribution asymÃ©trique â†’ signe d'underfitting ou dâ€™overfitting selon la forme

## 5. Conclusion

Le dataset DATE.SET.csv constitue une base solide pour un projet complet de rÃ©gression :

## ğŸ”¹ Points forts

Target bien distribuÃ©e

Dataset propre

Compatible avec enrichissement (clÃ© client)

IdÃ©al pour ML tabulaire

## ğŸ”¹ Limites

Seulement 2 colonnes â†’ nÃ©cessite un enrichissement par jointures

Pas dâ€™information mÃ©tier sur la signification exacte de target

## ğŸ”¹ AmÃ©liorations possibles

Ajouter des variables comportementales / socio-dÃ©mographiques

Tester XGBoost et LightGBM

Ajouter SHAP / LIME pour lâ€™explicabilitÃ©

Packager le modÃ¨le dans une API + pipeline MLOps









