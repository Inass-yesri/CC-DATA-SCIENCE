## ğŸ“„ DÃ©tection de Fraude â€“ Compte Rendu du Projet
<img width="400" height="250" alt="image" src="https://github.com/user-attachments/assets/a2c3ebce-f022-4246-843e-c58dcda56ea8" />

Machine Learning â€“ DÃ©tection de transactions suspectes

## ğŸŸ¦ 1. Introduction

## ğŸ¯ Contexte

Dans le secteur financier, la dÃ©tection automatique des transactions frauduleuses est un enjeu majeur.

Chaque jour, des millions dâ€™opÃ©rations sont effectuÃ©es, et seule une infime partie correspond Ã  des fraudes.

Les institutions doivent donc identifier ces anomalies rapidement, fiablement et sans intervention manuelle.

## ğŸ§© ProblÃ©matique

Comment dÃ©tecter automatiquement des transactions frauduleuses parmi des millions dâ€™opÃ©rations financiÃ¨res, dans un contexte oÃ¹ les fraudes sont rares et difficiles Ã  repÃ©rer ?

## Les dÃ©fis sont multiples :

DÃ©sÃ©quilibre important entre transactions normales et frauduleuses.

Volume massif de donnÃ©es.

VariabilitÃ© des comportements utilisateurs.

Fraudeurs qui modifient leurs stratÃ©gies.

## ğŸ¯ Objectifs du projet

Construire un pipeline complet dâ€™analyse et de modÃ©lisation.

Explorer les donnÃ©es pour comprendre les patterns de fraude.

PrÃ©traiter et nettoyer les donnÃ©es (encodage, normalisation, gestion du dÃ©sÃ©quilibre).

Comparer plusieurs modÃ¨les de Machine Learning supervisÃ©.

Ã‰valuer la performance via des mÃ©triques robustes (Recall, F1-Score, ROC-AUC).

Analyser les erreurs pour identifier les limites du systÃ¨me.

## ğŸŸ¦ 2. MÃ©thodologie

## ğŸ”§ 2.1. Dataset utilisÃ©

Dataset : PaySim â€“ Synthetic Financial Fraud Detection Dataset

## Taille : 6 millions de transactions

## Proportion de fraude : extrÃªmement faible (~0.1%)

Pourquoi ce dataset ?

## âœ”ï¸ DonnÃ©es financiÃ¨res rÃ©elles simulÃ©es

## âœ”ï¸ Fort dÃ©sÃ©quilibre â†’ parfait pour la fraude

## âœ”ï¸ DonnÃ©es massives â†’ cas rÃ©el

âœ”ï¸ Variables catÃ©gorielles + numÃ©riques â†’ modÃ¨le polyvalent

## ğŸ§¼ 2.2. PrÃ©traitement & Nettoyage

## âœ”ï¸ Encodage des variables catÃ©gorielles

La colonne type contient des valeurs textuelles (CASH-IN, TRANSFER...).

â¡ï¸ One-Hot Encoding choisi pour permettre une meilleure sÃ©paration linÃ©aire.

## âœ”ï¸ Normalisation des montants

Les colonnes amount et balance prÃ©sentent de grandes variations.

â¡ï¸ StandardScaler choisi pour faciliter la convergence des modÃ¨les linÃ©aires (Logistic Regression, SVM).

## âœ”ï¸ Gestion du dÃ©sÃ©quilibre

Le dataset est trÃ¨s dÃ©sÃ©quilibrÃ© (fraude â‰ª non fraude).

## Deux approches testÃ©es :

## class_weight="balanced"

## SMOTE pour gÃ©nÃ©rer des fraudes synthÃ©tiques

â¡ï¸ Le meilleur compromis a Ã©tÃ© obtenu avec class_weight, moins risquÃ© que SMOTE pour Ã©viter le surfitting.

## âš™ï¸ 2.3. ModÃ¨les testÃ©s

## Plusieurs algorithmes ont Ã©tÃ© Ã©valuÃ©s :

## ModÃ¨le	Avantages	InconvÃ©nients

Logistic Regression	Simple, rapide, baseline	Peu performant sur patterns complexes

Random Forest	Robuste, non linÃ©aire	Sensible au dÃ©sÃ©quilibre

XGBoost	TrÃ¨s performant, gÃ¨re bien l'imprÃ©visible	Long Ã  entraÃ®ner

Isolation Forest (Anomaly Detection)	IndÃ©pendant des labels	Faible prÃ©cision pour les fraudes

## Choix final :

ğŸ‘‰ Random Forest & XGBoost, car ce sont les modÃ¨les les plus adaptÃ©s aux patterns non linÃ©aires et au dÃ©sÃ©quilibre.

## ğŸŸ¦ 3. RÃ©sultats & Discussion

Lâ€™Ã©valuation sâ€™effectue sur plusieurs mÃ©triques, car dans un contexte de fraude :

â— Lâ€™accuracy nâ€™est pas fiable (un modÃ¨le peut avoir 99.9% dâ€™accuracy et rater toutes les fraudes).

## ğŸ“Š 3.1. Matrice de confusion

## PrÃ©dit

## 0         1

## RÃ©el  0       TN        FP

## 1       FN        TP

## Points analysÃ©s :

FN (False Negatives) : transactions frauduleuses non dÃ©tectÃ©es â†’ les plus critiques.

FP (False Positives) : transactions normales signalÃ©es Ã  tort â†’ coÃ»t opÃ©rationnel.

Un bon modÃ¨le doit maximiser le Recall tout en maintenant un F1 Ã©levÃ©.

## ğŸ“ˆ 3.2. MÃ©triques obtenues

## MÃ©trique	Score

## Accuracy	Ã©levÃ©e mais peu informative

## Precision	correcte

Recall (important)	Ã©levÃ© â†’ peu de fraudes manquÃ©es

## F1-Score	bon compromis

## ROC-AUC	> 0.95, excellent

## InterprÃ©tation :

Le modÃ¨le dÃ©tecte la plupart des fraudes.

Il gÃ©nÃ¨re un certain nombre de faux positifs (normal en contexte bancaire).

Un bon rappel signifie que le modÃ¨le "rate" trÃ¨s peu de fraudes, ce qui est crucial.

## ğŸ§  3.3. Analyse des erreurs

## Les erreurs les plus frÃ©quentes concernent :

Transactions avec montant faible mais comportement anormal (difficile Ã  capturer).

Patterns de fraude sophistiquÃ©s proches des comportements normaux.

Cas oÃ¹ le solde destination/origine suit des schÃ©mas rÃ©guliers malgrÃ© une fraude.

## Ces erreurs sont typiques lorsque :

## Le dataset est simulÃ©

## La fraude Ã©volue dans le temps

## ğŸŸ¦ 4. Conclusion

## âœ”ï¸ Ce que le modÃ¨le rÃ©ussit bien

TrÃ¨s bonne capacitÃ© Ã  dÃ©tecter les fraudes (Recall Ã©levÃ©).

ROC-AUC excellent â†’ modÃ¨le capable de sÃ©parer les classes.

AdaptÃ© Ã  des donnÃ©es volumineuses.

## âŒ Limites du modÃ¨le

Faux positifs encore trop nombreux â†’ coÃ»t opÃ©rationnel.

DonnÃ©es simulÃ©es â†’ comportements parfois simplifiÃ©s.

DÃ©pend fortement des features disponibles.

## ğŸš€ Pistes dâ€™amÃ©lioration

IntÃ©grer des modÃ¨les complexes : Deep Learning, Autoencoders, GNN.

Ajouter des informations temporelles (sÃ©quence de transactions).

## Utiliser des approches hybrides :

## Anomaly Detection + Classification

## Ensembles de modÃ¨les (Stacking)

Ajouter un systÃ¨me en ligne (mise Ã  jour continue du modÃ¨le).

## ğŸŸ© 5. RÃ©fÃ©rences

## Dataset PaySim â€“ Kaggle

## Algorithmes : Scikit-learn, XGBoost

## MÃ©triques ML standard : Precision, Recall, AUC
